{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/20192.ai4eng/master/init.py\n", "import init; init.init(force_download=False); init.get_weblink()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "## Based on [Kaggle House Pricing Prediction Competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/)\n", "\n", "- Inspect and learn from the competition [Notebooks](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/notebooks)\n", "- You must make available to this notebook the `train.csv` file from the competition [data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) section. If running this notebook in Google Colab you must upload it in the notebook files section in Colab."]}, {"cell_type": "code", "execution_count": 176, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import seaborn as sns\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from progressbar import progressbar as pbar\n", "from local.lib import mlutils\n", "%matplotlib inline\n", "d = pd.read_csv(\"/home/rlx/Downloads/train.csv\", index_col=\"Id\")\n", "d.head()"]}, {"cell_type": "code", "execution_count": 178, "metadata": {}, "outputs": [], "source": ["print (d.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# We must repair the missing data in the following columns\n", "\n", "**Possible repair actions**:\n", "\n", "- Remove row or column\n", "- Replace value (why what?)"]}, {"cell_type": "code", "execution_count": 179, "metadata": {}, "outputs": [], "source": ["k = d.isna().sum()\n", "k[k!=0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Inspect and understand missing data"]}, {"cell_type": "code", "execution_count": 180, "metadata": {}, "outputs": [], "source": ["def plot_missing(col, target):\n", "    \n", "    def f1(): \n", "        if d[col].dtype==object:\n", "            k = d[col].fillna(\"missing\").value_counts()\n", "            sns.barplot(k.index, k.values)\n", "        else:\n", "            sns.distplot(d[col].dropna())\n", "        plt.title(\"distribution of %s\"%col)\n", "        plt.grid()\n", "        \n", "    def f2(): \n", "        if d[col].dtype==object:\n", "            k=d[[col,target]].dropna()\n", "            for v in d[col].dropna().unique():\n", "                if sum(k[col]==v)>1:\n", "                    sns.distplot(k[target][k[col]==v], \n", "                                 hist_kws=dict(alpha=.3), \n", "                                 kde_kws=dict(linewidth=1, alpha=.8),\n", "                                 label=v);\n", "            if sum(d[col].isna())>1:\n", "                sns.distplot(d[target][d[col].isna()], \n", "                             hist_kws=dict(alpha=.8), \n", "                             kde_kws=dict(linewidth=1, alpha=1),\n", "                             label=\"missing\")\n", "            plt.legend();\n", "        else:\n", "            plt.scatter(d[col], d[target], alpha=.5)\n", "            plt.xlabel(target)\n", "            plt.ylabel(col)\n", "        plt.grid()\n", "        plt.title(\"%s vs target\"%(col))\n", "        \n", "    def f3(): \n", "        n = np.sum(d[col].isna())\n", "        if n>1:\n", "            sns.distplot(d[target][d[col].isna()], color=\"red\",  hist_kws=dict(alpha=.3), label=\"missing (%d values)\"%n)\n", "        sns.distplot(d[target][~d[col].isna()], color=\"blue\",  hist_kws=dict(alpha=.3), label=\"ok (%d values)\"%(len(d)-n))\n", "        plt.title(\"distribution of target wrt %s\"%col)\n", "        plt.yticks([])\n", "        plt.grid()\n", "        plt.legend()\n", "        \n", "    mlutils.figures_grid(3,1, [f1, f2, f3], figsize=(20,3))\n"]}, {"cell_type": "code", "execution_count": 181, "metadata": {"scrolled": false}, "outputs": [], "source": ["for col in k[k!=0].index:\n", "    plot_missing(col, target=\"SalePrice\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### common sense\n", "\n", "- too many missing data in **Alley**. Information might only help non-missing items with little impact on\n", "- missing data in **Bsmt\\*** seem all the same\n", "- missing data in **Garage\\*** sell all the same"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## For continuous variables"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Three substitution techniques\n", "\n", "- by a fixed value (zero)\n", "- by a fixed value (the mean)\n", "- sampling from an equivalent normal (same mean and std)\n", "\n", "**First** we create the different datasets:\n", "\n", "- `dn`: original data only with numerical attributes\n", "- `dl0`: substituting missing values with zero\n", "- `dlm`: substituting missing values with the mean\n", "- `dlr`: substituting missing values with an equivalent normal (same mean and stdev)"]}, {"cell_type": "code", "execution_count": 182, "metadata": {}, "outputs": [], "source": ["def xdistplot(k, title=\"\", xlim=None):\n", "    vals = k\n", "    sns.distplot(k, hist_kws={\"alpha\": .8});\n", "    m,s = np.mean(vals), np.std(vals)\n", "    plt.axvline(m, color=\"black\", lw=2, alpha=.5)\n", "    plt.axvline(m+s, color=\"red\", lw=2, alpha=.5)\n", "    plt.axvline(m-s, color=\"red\", lw=2, alpha=.5)\n", "    x = np.linspace(np.min(vals), np.max(vals), 100)\n", "    plt.title(title)\n", "    plt.grid();\n", "    if xlim is not None:\n", "        plt.xlim(xlim)"]}, {"cell_type": "code", "execution_count": 316, "metadata": {}, "outputs": [], "source": ["def subs_policies(d, col):\n", "    mcol = \"%s_missing\"%col\n", "    dn = d.T.dropna().T\n", "    dn = dn[[i for i in dn.columns if d[i].dtype!=object]]\n", "    print (dn.shape)\n", "    \n", "    na_idxs = np.argwhere(d[col].isna())[:,0]\n", "\n", "    dl0 = dn.copy()\n", "    dlm = dn.copy()\n", "    dlr = dn.copy()\n", "\n", "    dl0[mcol] = d[col].fillna(0)\n", "    dlm[mcol] = d[col].fillna( d[col].mean())\n", "\n", "    k = d[col].copy()\n", "    k[k.isna()] = np.random.normal(loc=np.mean(k), scale=np.std(k), size=np.sum(k.isna()))\n", "    dlr[mcol] = k\n", "\n", "    f0 = lambda: xdistplot(d[col].dropna(), \"original\", [0,150])\n", "    f1 = lambda: xdistplot(dl0[mcol], \"subs by zero\", [0,150])\n", "    f2 = lambda: xdistplot(dlm[mcol], \"subs by mean\", [0,150])\n", "    f3 = lambda: xdistplot(dlr[mcol], \"subs by equivalent normal\", [0,150])\n", "\n", "    mlutils.figures_grid(4,1, [f0, f1, f2, f3], figsize=(20,3))\n", "    return dn, dl0, dlm, dlr, na_idxs"]}, {"cell_type": "code", "execution_count": 317, "metadata": {}, "outputs": [], "source": ["dn, dl0, dl0, dlr, na_idxs = subs_policies(d, \"LotFrontage\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Validation workflow for repairing missing values on **LotFrontage**\n", "\n", "**Which policy for repairing missing data is best?**\n", "\n", "Short answer: **we do not know** $\\rightarrow$ **we must seek evidence**\n", "\n", "We will now integrate them in an ML workflow, creating predictive models and seeking for evidence if models improve or not when using different policies for repairing missing data.\n", "\n", "We train a lot of models (resampling training data) with each dataset and then run a classical hypothesis test on model performance:\n", "    \n", "- $e_1$: control group, models trained without **LotFrontage**\n", "- $e_2$: population group, models trained with **LotFrontage** with fillna=0\n", "\n", "Our null hypothesis (there is no effect in using the new variable):\n", "\n", "$$H_0: \\mu_{e_1}-\\mu_{e_2}=0 \\Rightarrow \\mu_{e_1-e_2}=0$$\n", "\n", "Our test hypothesis (including fillna=0 improves models):\n", "\n", "$$H_1: \\mu_{e_1}-\\mu_{e_2}<0 \\Rightarrow \\mu_{e_1-e_2}<0$$\n"]}, {"cell_type": "code", "execution_count": 393, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import cross_val_score, ShuffleSplit\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error, make_scorer\n", "from scipy.stats import ttest_ind\n", "\n", "def getXY (dn):\n", "    xcols = [i for i in dn.columns if i!=\"SalePrice\"]\n", "    X = dn[xcols].values.astype(float)\n", "    y = dn.SalePrice.values.astype(float)\n", "    return X,y,xcols\n", "\n", "def experiment(dn, estimator, n_models=20, test_size=.3):\n", "    X,y,_ = getXY(dn)\n", "    r = cross_val_score(estimator, X, y, cv=ShuffleSplit(n_models, test_size=test_size), \n", "                        scoring=make_scorer(mean_absolute_error))\n", "    return r\n", "\n", "def HTest(ref_dataset, h_datasets, n_models=30, experiment=experiment, **kwargs):\n", "    estimator = RandomForestRegressor(n_estimators=20)\n", "    re = [experiment(i, estimator, n_models=n_models, **kwargs) for i in pbar([ref_dataset]+h_datasets)]\n", "\n", "    for r in re[1:]:\n", "        print (ttest_ind(re[0],r))\n"]}, {"cell_type": "code", "execution_count": 383, "metadata": {}, "outputs": [], "source": ["dl0.head()"]}, {"cell_type": "code", "execution_count": 408, "metadata": {}, "outputs": [], "source": ["HTest(dn, [dl0, dlm, dlr], n_models=50)"]}, {"cell_type": "code", "execution_count": 409, "metadata": {}, "outputs": [], "source": ["HTest(dn, [dl0, dlm, dlr], n_models=50)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["No $p$ value is really significative so the different substitution policies do no help improve overall in this simplified setting. More over, repeated experiments show to evidence of any approach better than others (always better $p$ value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Some models provide us with a measure of **feature importance**. Observe the behaviour of the most important variables in the scatter matrix plot of previous notebook."]}, {"cell_type": "code", "execution_count": 416, "metadata": {}, "outputs": [], "source": ["X, y, xcols = getXY(dlr)\n", "rf = RandomForestRegressor(n_estimators=20)\n", "rf.fit(X,y);\n", "plt.figure(figsize=(10,2)); plt.grid()\n", "plt.plot(rf.feature_importances_, label=\"est1\", marker=\"x\")\n", "plt.xticks(range(len(xcols)), xcols, rotation=\"vertical\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["so somehow it is understandable that providing values for this missing variable does not have so much impact.\n", "\n", "We could try to see **ONLY** records with **THIS** missing data behave."]}, {"cell_type": "code", "execution_count": 394, "metadata": {}, "outputs": [], "source": ["def na_cross_val_score(estimator, X, y, cv, scoring, val_idxs):\n", "    r = []\n", "    for tr_idxs, ts_idxs in cv.split(X):\n", "        tr_idxs, ts_idxs = np.r_[tr_idxs], np.r_[ts_idxs]\n", "        rf.fit(X[tr_idxs], y[tr_idxs])\n", "        valts_idxs = np.r_[[i for i in ts_idxs if i in val_idxs]]\n", "        r.append(scoring(rf, X[valts_idxs], y[valts_idxs]))    \n", "    return r\n", "\n", "\n", "def na_experiment(dn, estimator, na_idxs, n_models=20, test_size=.3):\n", "    X,y,_ = getXY(dn)\n", "    r = na_cross_val_score(estimator, X, y, cv=ShuffleSplit(n_models, test_size=test_size), \n", "                        scoring=make_scorer(mean_absolute_error), val_idxs=na_idxs)\n", "    return r\n"]}, {"cell_type": "code", "execution_count": 406, "metadata": {}, "outputs": [], "source": ["HTest(dn, [dl0, dlm, dlr], experiment=na_experiment, na_idxs=na_idxs, n_models=50)"]}, {"cell_type": "code", "execution_count": 407, "metadata": {}, "outputs": [], "source": ["HTest(dn, [dl0, dlm, dlr], experiment=na_experiment, na_idxs=na_idxs, n_models=50)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## For categorical features\n", "\n", "- we must convert them to numerical\n", "    - if categories are **ordered** $\\rightarrow$ convert to positive integer\n", "    - otherwise $\\rightarrow$ convert to one hot\n", "- we must decide on missing values:\n", "    - remove row or column\n", "    - assign an existing value\n", "    - assign a new value"]}, {"cell_type": "code", "execution_count": 334, "metadata": {}, "outputs": [], "source": ["col = \"GarageFinish\"\n", "print (\"missing\", sum(d[col].isna()))\n", "d[col].value_counts()"]}, {"cell_type": "code", "execution_count": 364, "metadata": {}, "outputs": [], "source": ["def to_onehot(x):\n", "    values = np.unique(x)\n", "    r = np.r_[[np.argwhere(i==values)[0][0] for i in x]]\n", "    return np.eye(len(values))[r].astype(int)\n", "\n", "def replace_column_with_onehot(d, col):\n", "    assert sum(d[col].isna())==0, \"column must have no NaN values\"\n", "    values = np.unique(d[col]\n", "                      )\n", "    k = to_onehot(d[col].values)\n", "    r = pd.DataFrame(k, columns=[\"%s_%s\"%(col, values[i]) for i in range(k.shape[1])], index=d.index).join(d)\n", "    del(r[col])\n", "    return r"]}, {"cell_type": "markdown", "metadata": {}, "source": ["observe **onehot** encoding"]}, {"cell_type": "code", "execution_count": 365, "metadata": {}, "outputs": [], "source": ["d[[col]].head(10)"]}, {"cell_type": "code", "execution_count": 366, "metadata": {}, "outputs": [], "source": ["replace_column_with_onehot(d[[col]].dropna().copy(), col).head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["we now create a onehot encoding for each case:\n", "- create a separate value for missing data\n", "- set missing data to an existing category. In this case we will set it to the closest category distribution wrt the target variable according the plots above"]}, {"cell_type": "code", "execution_count": 367, "metadata": {}, "outputs": [], "source": ["rm1 = replace_column_with_onehot(d[[col]].fillna(\"missing\").copy(), col)\n", "rm2 = replace_column_with_onehot(d[[col]].fillna(\"Unf\").copy(), col)"]}, {"cell_type": "code", "execution_count": 368, "metadata": {}, "outputs": [], "source": ["rm1.head()"]}, {"cell_type": "code", "execution_count": 369, "metadata": {}, "outputs": [], "source": ["rm2.head()"]}, {"cell_type": "code", "execution_count": 391, "metadata": {}, "outputs": [], "source": ["dm1 = dn.join(rm1)\n", "dm2 = dn.join(rm2)\n", "dm1.shape, dm2.shape"]}, {"cell_type": "code", "execution_count": 410, "metadata": {}, "outputs": [], "source": ["HTest(dn, [dm1, dm2], experiment=experiment, n_models=50)"]}, {"cell_type": "code", "execution_count": 412, "metadata": {}, "outputs": [], "source": ["na_idxs = np.argwhere(d[col].isna())[:,0]\n", "HTest(dn, [dm1, dm2], experiment=na_experiment, na_idxs=na_idxs, n_models=50)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Again, no $p$ value is sufficiently significative to provide evidence for improved classification alone. However, approach number 2 (substituting missing data with **Unf**) does seem to consistently get better $p$ value and, thus, more chance to improve performance when combined with other data cleaning choices. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Observe also how the **missing** category dilutes the importance of **Unf** after other variables are taken out."]}, {"cell_type": "code", "execution_count": 434, "metadata": {}, "outputs": [], "source": ["dk = dm2.copy()\n", "dk = dk[[i for i in dm2.columns if not i in [\"OverallQual\", \"GarageCars\", \"GrLivArea\", \n", "                                             \"GarageArea\", \"YearBuilt\", \"TotalBsmtSF\",\n", "                                            \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\"]]]\n", "X, y, xcols = getXY(dk)\n", "rf = RandomForestRegressor(n_estimators=10)\n", "rf.fit(X,y);\n", "plt.figure(figsize=(10,2)); plt.grid()\n", "plt.plot(rf.feature_importances_, label=\"est1\", marker=\"x\")\n", "plt.xticks(range(len(xcols)), xcols, rotation=\"vertical\");"]}, {"cell_type": "code", "execution_count": 435, "metadata": {}, "outputs": [], "source": ["dk = dm1.copy()\n", "dk = dk[[i for i in dm1.columns if not i in [\"OverallQual\", \"GarageCars\", \"GrLivArea\", \n", "                                             \"GarageArea\", \"YearBuilt\", \"TotalBsmtSF\",\n", "                                            \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\"]]]\n", "X, y, xcols = getXY(dk)\n", "rf = RandomForestRegressor(n_estimators=10)\n", "rf.fit(X,y);\n", "plt.figure(figsize=(10,2)); plt.grid()\n", "plt.plot(rf.feature_importances_, label=\"est1\", marker=\"x\")\n", "plt.xticks(range(len(xcols)), xcols, rotation=\"vertical\");"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "p36cpu", "language": "python", "name": "p36cpu"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.7"}}, "nbformat": 4, "nbformat_minor": 2}